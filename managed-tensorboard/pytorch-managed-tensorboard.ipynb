{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring PyTorch experiments with AI Platform TensorBoard\n",
    "\n",
    "This code sample demonstrates how to configure AI Platform TensorBoard (Experimental) to monitor PyTorch training jobs.\n",
    "\n",
    "AI Platform Tensorboard is an enterprise ready, managed version of TensorBoard, a Google Open Source project for Machine Learning experiment visualization, that is tightly integrated with the Google Cloud AI Platform.\n",
    "\n",
    "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
    "* Tracking and visualizing metrics such as loss and accuracy\n",
    "* Visualizing the model graph (ops and layers)\n",
    "* Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "* Projecting embeddings to a lower dimensional space\n",
    "* Displaying images, text, and audio data\n",
    "* Profiling TensorFlow programs\n",
    "* And much more\n",
    "\n",
    "Note that currently, AI Platform TensorBoard requires AI Platform Training and only supports the Scalars dashboard. As support for other features of TensorBoard are added this notebook will be updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "This notebook was designed to run on [AI Platform Notebooks](https://cloud.google.com/ai-platform/notebooks/docs) using the standard PyTorch 1.6+ image. Your notebook instance should be in the same project as the AI Platform TensorBoard and Training services.\n",
    "\n",
    "While AI Platform TensorBoard is in the Experimental stage your project must be allow-listed before using the service. Use the [signup form](https://docs.google.com/forms/d/e/1FAIpQLSfbvZ5xrFStX54qEUlJ6A0tWZ-O20i_t-Hifm0JvbX8do5IcQ/viewform) to request the acccess.\n",
    "\n",
    "After your project has been allow-listed make sure to [enable Cloud AI Platform API](https://console.cloud.google.com/apis/library/aiplatform.googleapis.com?q=cloud%20ai%20platform%20api&id=6189b0c0-23b1-46a4-a32f-70639e83fe9b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You will use AI Platform TensorBoard to monitor PyTorch AI Platform Training jobs. The training scenario is transfer learning for an image classification problem, inspired by the Kaggle's classic Dogs vs. Cats competition. \n",
    "\n",
    "You will run and monitor two types of AI Platform Training jobs: a custom training job and a hyperparameter tuning job. Both types of jobs will utilize the same custom docker image that encapsulates the training application and the PyTorch runtime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import google.auth\n",
    "\n",
    "from google.auth.credentials import Credentials\n",
    "from google.auth.transport.requests import AuthorizedSession\n",
    "\n",
    "from typing import List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AI Platform Training service account\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate with AI Platform TensorBoard, AI Platform Training jobs have to run in the context a service account that has permisions to write logs to GCS and access the AI Platform TensorBoard service. \n",
    "\n",
    "If you don't have one already set up, create and configure a new service account using the following instructions. Note that by default, your AI Platform Notebook instance is running under the **Compute Engine default service account** that does not have the required permissions (specifically `iam.serviceAccounts.setIamPolicy`) to configure the service account. If this is the case, use a different environment  (for example **Cloud Shell**) and the account with the required permissions to run the below commands.\n",
    "\n",
    "\n",
    "1. Create a service account\n",
    "\n",
    "```\n",
    "PROJECT_ID=[YOUR_PROJECT_ID]\n",
    "USER_SA_NAME=[YOUR_SA_ACCOUNT_NAME]\n",
    "\n",
    "gcloud --project=$PROJECT_ID iam service-accounts create $USER_SA_NAME\n",
    "\n",
    "```\n",
    "\n",
    "2. Retrieve the internal service account used by AI Platform \n",
    "\n",
    "```\n",
    "GOOGLE_SA=$(gcloud projects get-iam-policy $PROJECT_ID \\\n",
    "    --flatten=\"bindings[].members\" --format=\"table(bindings.members)\" \\\n",
    "    --filter=\"bindings.role:roles/aiplatform.customCodeServiceAgent\" | \\\n",
    "    grep \"serviceAccount:\" | head -n1)\n",
    "```\n",
    "\n",
    "3. Give the AI Platform service account permissions to impersonate your service account\n",
    "\n",
    "```\n",
    "SA_EMAIL=\"${USER_SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com\"\n",
    "\n",
    "gcloud --project=$PROJECT_ID iam service-accounts add-iam-policy-binding \\\n",
    "    --role roles/iam.serviceAccountAdmin \\\n",
    "    --member $GOOGLE_SA $SA_EMAIL\n",
    "\n",
    "```\n",
    "\n",
    "4. Give your service account access to GCS and AI Platform Tensorboard service.\n",
    "\n",
    "```\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:${SA_EMAIL}\" \\\n",
    "    --role=\"roles/storage.admin\"\n",
    "\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:${SA_EMAIL}\" \\\n",
    "    --role=\"roles/aiplatform.user\"\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Set the `SA_EMAIL` constant to the email account of your service account. If you followed the above steps to create the account you can display it by:\n",
    "\n",
    "```\n",
    "echo $SA_EMAIL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_EMAIL = 'aip-training@jk-mlops-dev.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set AI Platform (Unified) constants\n",
    "\n",
    "`PROJECT_ID` - The GCP Project ID. Both your AI Platform Notebook instance and AI Platform Training jobs should be in the same project. Make sure to modify the placeholder with your Project ID.\n",
    "\n",
    "`CAIP_REGION` - A GCP compute region to use for the cloud services used in this notebook. Make sure to choose a region where [Cloud AI Platform services](https://cloud.google.com/ml-engine/docs/tensorflow/regions) are available. The default region is `us-central1`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "CAIP_REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current version of AI Platform (Unified) Python SDK does not support the AI Platform TensorBoard service nor the AI Platform Training service intergration with AI Platform TensorBoard. To mitigate, the notebook calls the APIs directly using the REST interface. You don't need to change the below constants that define the API's endpoint and root resource paths. \n",
    "\n",
    "`CAIP_ENDPOINT` - The AI Platform (Unified) API service endpoint.\n",
    "\n",
    "`CAIP_PARENT_ALPHA` - The AI Platform (Unified) Alpha (Experimental) API root resource path. AI Platform (Unified) TensorBoard is in the Experimental stage.\n",
    "\n",
    "`CAIP_PARENT_BETA` - The AI Platform (Unified) Beta (Preview) API root resource path. AI Platform (Unified) Training is in the Preview stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAIP_ENDPOINT = f'{CAIP_REGION}-aiplatform.googleapis.com'\n",
    "CAIP_PARENT_ALPHA = f'https://{CAIP_ENDPOINT}/v1alpha1/projects/{PROJECT_ID}/locations/{CAIP_REGION}'\n",
    "CAIP_PARENT_BETA = f'https://{CAIP_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{CAIP_REGION}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a GCS bucket to store TensorBoard logs\n",
    "\n",
    "The training script writes TensorBoard logs to a GCS bucket from which the AI Platform Training service  ingests them to the TensorBoard service. The GCS bucket should be a regional bucket  in the same region where the training job is executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://jk-mlops-dev-tensorboard-logs/...\n"
     ]
    }
   ],
   "source": [
    "GCS_BUCKET_NAME = f'{PROJECT_ID}-tensorboard-logs'\n",
    "\n",
    "!gsutil mb -l {CAIP_REGION} gs://{GCS_BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TensorBoard instance\n",
    "\n",
    "You will now create an AI Platform TensorBoard instance. As noted before you will use the REST interface to invoke the AI Platform TensorBoard API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an authorized session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials, _ = google.auth.default()\n",
    "authed_session = AuthorizedSession(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a TensorBoard resorce\n",
    "\n",
    "The following REST call creates a TensorBoard resource and sets its display name. Note that multiple resources can share the same display name, so each execution of the following cell creates a new TensorBoard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_display_name = 'pytorch_tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/895222332033/locations/us-central1/tensorboards/2152439146906386432/operations/8989011133394321408',\n",
       " 'metadata': {'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.CreateTensorboardOperationMetadata',\n",
       "  'genericMetadata': {'createTime': '2020-12-08T00:53:29.144269Z',\n",
       "   'updateTime': '2020-12-08T00:53:29.144269Z'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = f'{CAIP_PARENT_ALPHA}/tensorboards'\n",
    "\n",
    "request_body = {\n",
    "    'display_name': tensorboard_display_name\n",
    "}\n",
    "\n",
    "response = authed_session.post(api_url, data=json.dumps(request_body))\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List TensorBoard instances \n",
    "\n",
    "To verify that the instance was succesfully created list all instances with the set display name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensorboards': [{'name': 'projects/895222332033/locations/us-central1/tensorboards/2152439146906386432',\n",
       "   'displayName': 'pytorch_tensorboard',\n",
       "   'createTime': '2020-12-08T00:53:29.144269Z',\n",
       "   'updateTime': '2020-12-08T00:53:29.345030Z',\n",
       "   'etag': 'AMEw9yNS6EIF5uzD3Ze0iP7UoEHXtMmXORoc_x9diWExZgC-S5sVPwJCOf9bAWgKKkBn'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = f'{CAIP_PARENT_ALPHA}/tensorboards?filter=display_name={tensorboard_display_name}'\n",
    "\n",
    "response = authed_session.get(api_url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve a full name of your instance\n",
    "\n",
    "You can retrieve the fullname of the created instance from the JSON response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/895222332033/locations/us-central1/tensorboards/2152439146906386432'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_id = response.json()['tensorboards'][0]['name']\n",
    "tensorboard_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your environment is ready. You will now create a custom PyTorch training container image and submit and monitor AI Platform Training jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a training container image\n",
    "\n",
    "There are two ways to create AI Platform Training jobs:\n",
    "\n",
    "* **Using a Google Cloud prebuilt container image**. If you use a prebuilt container, you have to prepare a Python package that is installed on top of the pre-built container image when you submit the job. This Python package contains your code for training a model. The pre-built container provides a runtime environment - e.g. TensorFlow. There is a number of pre-built container images available providing pre-configured environments for the most popular frameworks, including TensorFlow, PyTorch, XGBoost and Scikit-learn.\n",
    "\n",
    "* **Using your own custom container image**. You are responsible for creating the container image including packaging your training code and all its dependencies.\n",
    "\n",
    "This notebook uses the second approach. You will build your own custom container image that will be a derivative of the standard PyTorch [Deep Learning container](https://cloud.google.com/ai-platform/deep-learning-containers/docs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script\n",
    "\n",
    "The first step is to create a training script. If you want to provide runtime paramaters that control the execution of the script they should be provided as command line arguments.\n",
    "\n",
    "Take the time to review the script:\n",
    "\n",
    "* The `get_catsanddogs` function creates PyTorch training and validation datasets (`torch.utils.data.Dataset`) using images of cats and dogs, downloaded from `https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip`\n",
    "* The `get_model` function creates the CNN that is based on the pre-trained ResNet18 model and includes a simple, custom FCNN classification head\n",
    "* The `train_eval` function implement a training and evaluation loop. Note the use of `torch.utils.tensorboard` to log the training and validation losses and the validation accuracy to the TensorBoard log. Also check, how the `hypertune` package is used to report the validation accuracy to AI Platform Training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_eval.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_eval.py\n",
    "\n",
    "# Copyright 2020 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import argparse\n",
    "import hypertune\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "DEFAULT_ROOT = '/tmp'\n",
    "\n",
    "def get_catsanddogs(root):\n",
    "    \"\"\"\n",
    "    Creates training and validation Datasets based on images\n",
    "    of cats and dogs from \n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download and extract the images\n",
    "    source_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "    local_filename = source_url.split('/')[-1]\n",
    "    datasets.utils.download_url(source_url, root, )\n",
    "    path_to_zip = os.path.join(root, local_filename)\n",
    "    with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(root)\n",
    "    \n",
    "    \n",
    "    # Create datasets\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(path_to_zip[:-4], 'train'),\n",
    "        transform=train_transforms)\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(path_to_zip[:-4], 'validation'),\n",
    "        transform=val_transforms\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "    \n",
    "\n",
    "\n",
    "def get_model(num_layers, dropout_ratio, num_classes):\n",
    "    \"\"\"\n",
    "    Creates a convolution net using ResNet50 trunk and\n",
    "    a custom head.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the ResNet50 trunk\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Get the number of input features to the default head\n",
    "    num_features = model.fc.in_features\n",
    "\n",
    "    # Freeze trunk weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Define the new head\n",
    "    head = nn.Sequential(nn.Linear(num_features, num_layers),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(dropout_ratio),\n",
    "                         nn.Linear(num_layers, num_classes))\n",
    "\n",
    "    # Replace the head\n",
    "    model.fc = head\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_eval(device, model, train_dataloader, valid_dataloader,\n",
    "               criterion, optimizer, scheduler, num_epochs, writer=None):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model.\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    hpt = hypertune.HyperTune()\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        num_train_examples = 0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_train_examples += inputs.size(0)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        num_val_examples = 0\n",
    "        val_loss = 0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for inputs, labels in valid_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            num_val_examples += inputs.size(0)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(torch.eq(torch.max(outputs, 1)\n",
    "                                               [1], labels))\n",
    "\n",
    "        # Log epoch metrics\n",
    "        train_loss = train_loss / num_train_examples\n",
    "        val_loss = val_loss / num_val_examples\n",
    "        val_acc = val_corrects.double() / num_val_examples\n",
    "\n",
    "        print('Epoch: {}/{}, Training loss: {:.3f}, Validation loss: {:.3f}, Validation accuracy: {:.3f}'.format(\n",
    "              epoch, num_epochs, train_loss, val_loss, val_acc))\n",
    "\n",
    "        # Write to Tensorboard\n",
    "        if writer:\n",
    "            writer.add_scalars(\n",
    "                'Loss', {'training': train_loss, 'validation': val_loss}, epoch)\n",
    "            writer.add_scalar('Validation accuracy', val_acc, epoch)\n",
    "            writer.flush()\n",
    "            \n",
    "        # Report to HyperTune\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag='accuracy',\n",
    "            metric_value=val_acc,\n",
    "            global_step=epoch\n",
    "        )\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"\n",
    "    Returns parsed command line arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        type=int,\n",
    "        default=20,\n",
    "        help='number of times to go through the data, default=20')\n",
    "    parser.add_argument(\n",
    "        '--batch-size',\n",
    "        default=32,\n",
    "        type=int,\n",
    "        help='number of records to read during each training step, default=32')\n",
    "    parser.add_argument(\n",
    "        '--num-layers',\n",
    "        default=64,\n",
    "        type=int,\n",
    "        help='number of hidden layers in the classification head , default=64')\n",
    "    parser.add_argument(\n",
    "        '--dropout-ratio',\n",
    "        default=0.5,\n",
    "        type=float,\n",
    "        help='dropout ration in the classification head , default=128')\n",
    "    parser.add_argument(\n",
    "        '--step-size',\n",
    "        default=7,\n",
    "        type=int,\n",
    "        help='step size of LR scheduler')\n",
    "    parser.add_argument(\n",
    "        '--log-dir',\n",
    "        type=str,\n",
    "        default='/tmp',\n",
    "        help='directory for TensorBoard logs')\n",
    "    parser.add_argument(\n",
    "        '--verbosity',\n",
    "        choices=['DEBUG', 'ERROR', 'FATAL', 'INFO', 'WARN'],\n",
    "        default='INFO')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Parse command line arguments\n",
    "    args = get_args()\n",
    "    \n",
    "    # Create train and validation dataloaders\n",
    "    train_dataset, val_dataset = get_catsanddogs(DEFAULT_ROOT)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    class_names = train_dataset.classes\n",
    "    \n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('-' * 10)\n",
    "    print(f'Training on device: {device}')\n",
    "\n",
    "    # Configure training\n",
    "    model = get_model(args.num_layers, args.dropout_ratio, len(class_names))\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=args.step_size, gamma=0.1)\n",
    "\n",
    "    # Set location for the TensorBoard logs\n",
    "    if 'AIP_TENSORBOARD_LOG_DIR' in os.environ:\n",
    "        log_dir = os.environ['AIP_TENSORBOARD_LOG_DIR']\n",
    "    else:\n",
    "        log_dir = args.log_dir\n",
    "\n",
    "    with SummaryWriter(log_dir) as writer:\n",
    "        # Add sample normalized images to Tensorboard\n",
    "        images, _ = iter(train_dataloader).next()\n",
    "        img_grid = torchvision.utils.make_grid(images)\n",
    "        writer.add_image('Example images', img_grid)\n",
    "        # Add graph to Tensorboard\n",
    "        writer.add_graph(model, images)\n",
    "        trained_model, accuracy = train_eval(device, model, train_dataloader, val_dataloader,\n",
    "                                             criterion, optimizer, scheduler, args.num_epochs, writer)\n",
    "\n",
    "        # Add final results and hyperparams to Tensorboard\n",
    "        writer.add_hparams({\n",
    "            'batch_size': args.batch_size,\n",
    "            'hidden_layers': args.num_layers,\n",
    "            'dropout_ratio': args.dropout_ratio\n",
    "        },\n",
    "            {\n",
    "            'hparam/accuracy': accuracy\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dockerfile\n",
    "\n",
    "The training script is be packaged in a container image that is based on the standard PyTorch 1.6 Deep Learning container image - `gcr.io/deeplearning-platform-release/pytorch-gpu.1-6`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/pytorch-gpu.1-6\n",
    "    \n",
    "RUN pip install -U tensorflow cloudml-hypertune\n",
    "\n",
    "ADD train_eval.py .\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"train_eval.py\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image\n",
    "\n",
    "You will [Cloud Build](https://cloud.google.com/cloud-build/docs/) to build the image and push it to your project's [Container Registry](https://cloud.google.com/container-registry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = 'image_classifier'\n",
    "IMAGE_TAG = 'latest'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{IMAGE_TAG}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 8 file(s) totalling 153.6 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://jk-mlops-dev_cloudbuild/source/1607388892.08279-dec718e2d26d41a5a702882b460ad99d.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-mlops-dev/builds/57919f40-b3e9-48d4-8858-c92d5c6c5283].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/57919f40-b3e9-48d4-8858-c92d5c6c5283?project=895222332033].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"57919f40-b3e9-48d4-8858-c92d5c6c5283\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-mlops-dev_cloudbuild/source/1607388892.08279-dec718e2d26d41a5a702882b460ad99d.tgz#1607388892514737\n",
      "Copying gs://jk-mlops-dev_cloudbuild/source/1607388892.08279-dec718e2d26d41a5a702882b460ad99d.tgz#1607388892514737...\n",
      "/ [1 files][ 29.9 KiB/ 29.9 KiB]                                                \n",
      "Operation completed over 1 objects/29.9 KiB.                                     \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  164.4kB\n",
      "Step 1/4 : FROM gcr.io/deeplearning-platform-release/pytorch-gpu.1-6\n",
      "latest: Pulling from deeplearning-platform-release/pytorch-gpu.1-6\n",
      "171857c49d0f: Pulling fs layer\n",
      "419640447d26: Pulling fs layer\n",
      "61e52f862619: Pulling fs layer\n",
      "2a93278deddf: Pulling fs layer\n",
      "c9f080049843: Pulling fs layer\n",
      "8189556b2329: Pulling fs layer\n",
      "c306a0c97a55: Pulling fs layer\n",
      "4a9478bd0b24: Pulling fs layer\n",
      "19a76c31766d: Pulling fs layer\n",
      "8ea4312a805b: Pulling fs layer\n",
      "49c915c52a5e: Pulling fs layer\n",
      "97e35227d17a: Pulling fs layer\n",
      "826cd5eebb75: Pulling fs layer\n",
      "7abcc11123e7: Pulling fs layer\n",
      "1551564767ef: Pulling fs layer\n",
      "76c3c2a8417c: Pulling fs layer\n",
      "a5d29b3866d3: Pulling fs layer\n",
      "d4bd52dd7bac: Pulling fs layer\n",
      "06cd03101dcb: Pulling fs layer\n",
      "138db1711560: Pulling fs layer\n",
      "9038454ec001: Pulling fs layer\n",
      "da3609135049: Pulling fs layer\n",
      "9e03d509834a: Pulling fs layer\n",
      "9d0c6aa151e8: Pulling fs layer\n",
      "05809a49f65b: Pulling fs layer\n",
      "2a93278deddf: Waiting\n",
      "c9f080049843: Waiting\n",
      "8189556b2329: Waiting\n",
      "c306a0c97a55: Waiting\n",
      "4a9478bd0b24: Waiting\n",
      "19a76c31766d: Waiting\n",
      "8ea4312a805b: Waiting\n",
      "49c915c52a5e: Waiting\n",
      "97e35227d17a: Waiting\n",
      "826cd5eebb75: Waiting\n",
      "7abcc11123e7: Waiting\n",
      "1551564767ef: Waiting\n",
      "76c3c2a8417c: Waiting\n",
      "a5d29b3866d3: Waiting\n",
      "d4bd52dd7bac: Waiting\n",
      "06cd03101dcb: Waiting\n",
      "138db1711560: Waiting\n",
      "9038454ec001: Waiting\n",
      "da3609135049: Waiting\n",
      "9e03d509834a: Waiting\n",
      "9d0c6aa151e8: Waiting\n",
      "05809a49f65b: Waiting\n",
      "419640447d26: Verifying Checksum\n",
      "419640447d26: Download complete\n",
      "61e52f862619: Verifying Checksum\n",
      "61e52f862619: Download complete\n",
      "2a93278deddf: Verifying Checksum\n",
      "2a93278deddf: Download complete\n",
      "c9f080049843: Verifying Checksum\n",
      "c9f080049843: Download complete\n",
      "171857c49d0f: Verifying Checksum\n",
      "171857c49d0f: Download complete\n",
      "8189556b2329: Verifying Checksum\n",
      "8189556b2329: Download complete\n",
      "4a9478bd0b24: Verifying Checksum\n",
      "4a9478bd0b24: Download complete\n",
      "19a76c31766d: Verifying Checksum\n",
      "19a76c31766d: Download complete\n",
      "49c915c52a5e: Verifying Checksum\n",
      "49c915c52a5e: Download complete\n",
      "97e35227d17a: Verifying Checksum\n",
      "97e35227d17a: Download complete\n",
      "8ea4312a805b: Verifying Checksum\n",
      "8ea4312a805b: Download complete\n",
      "7abcc11123e7: Verifying Checksum\n",
      "7abcc11123e7: Download complete\n",
      "1551564767ef: Verifying Checksum\n",
      "1551564767ef: Download complete\n",
      "c306a0c97a55: Verifying Checksum\n",
      "c306a0c97a55: Download complete\n",
      "76c3c2a8417c: Verifying Checksum\n",
      "76c3c2a8417c: Download complete\n",
      "171857c49d0f: Pull complete\n",
      "826cd5eebb75: Verifying Checksum\n",
      "826cd5eebb75: Download complete\n",
      "a5d29b3866d3: Download complete\n",
      "06cd03101dcb: Verifying Checksum\n",
      "06cd03101dcb: Download complete\n",
      "138db1711560: Verifying Checksum\n",
      "138db1711560: Download complete\n",
      "9038454ec001: Download complete\n",
      "d4bd52dd7bac: Verifying Checksum\n",
      "d4bd52dd7bac: Download complete\n",
      "9e03d509834a: Verifying Checksum\n",
      "9e03d509834a: Download complete\n",
      "da3609135049: Verifying Checksum\n",
      "da3609135049: Download complete\n",
      "05809a49f65b: Verifying Checksum\n",
      "05809a49f65b: Download complete\n",
      "419640447d26: Pull complete\n",
      "61e52f862619: Pull complete\n",
      "2a93278deddf: Pull complete\n",
      "c9f080049843: Pull complete\n",
      "8189556b2329: Pull complete\n",
      "9d0c6aa151e8: Verifying Checksum\n",
      "9d0c6aa151e8: Download complete\n",
      "c306a0c97a55: Pull complete\n",
      "4a9478bd0b24: Pull complete\n",
      "19a76c31766d: Pull complete\n",
      "8ea4312a805b: Pull complete\n",
      "49c915c52a5e: Pull complete\n",
      "97e35227d17a: Pull complete\n",
      "826cd5eebb75: Pull complete\n",
      "7abcc11123e7: Pull complete\n",
      "1551564767ef: Pull complete\n",
      "76c3c2a8417c: Pull complete\n",
      "a5d29b3866d3: Pull complete\n",
      "d4bd52dd7bac: Pull complete\n",
      "06cd03101dcb: Pull complete\n",
      "138db1711560: Pull complete\n",
      "9038454ec001: Pull complete\n",
      "da3609135049: Pull complete\n",
      "9e03d509834a: Pull complete\n",
      "9d0c6aa151e8: Pull complete\n",
      "05809a49f65b: Pull complete\n",
      "Digest: sha256:19c6411647e17498e22b3e0073d78b119f812f1b4c3ed8d87da2701db2c4aad4\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:latest\n",
      " ---> 74315b2cf252\n",
      "Step 2/4 : RUN pip install -U tensorflow cloudml-hypertune\n",
      " ---> Running in ed32067d9046\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.33.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.6.0.post20201009)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Building wheels for collected packages: cloudml-hypertune, termcolor\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=980953ad86100f9f3a4ef4ffa677d39e656e937ea124c25c44c753a5912cf81e\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=232f1716490281ad964085d710233591238fd185cad0f6cb0f4642f00ddd2658\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built cloudml-hypertune termcolor\n",
      "Installing collected packages: astunparse, gast, absl-py, tensorflow-estimator, numpy, keras-preprocessing, opt-einsum, tensorboard-plugin-wit, tensorboard, termcolor, google-pasta, tensorflow, cloudml-hypertune\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.3\n",
      "    Uninstalling numpy-1.19.3:\n",
      "      Successfully uninstalled numpy-1.19.3\n",
      "\u001b[91mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "pandas-profiling 2.8.0 requires visions[type_image_path]==0.4.4, but you'll have visions 0.6.4 which is incompatible.\n",
      "\u001b[0mSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cloudml-hypertune-0.1.0.dev6 gast-0.3.3 google-pasta-0.2.0 keras-preprocessing-1.1.2 numpy-1.18.5 opt-einsum-3.3.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0\n",
      "Removing intermediate container ed32067d9046\n",
      " ---> 794d31ac055b\n",
      "Step 3/4 : ADD train_eval.py .\n",
      " ---> 00004f89da7d\n",
      "Step 4/4 : ENTRYPOINT [\"python3\", \"train_eval.py\"]\n",
      " ---> Running in dc7e67fea80f\n",
      "Removing intermediate container dc7e67fea80f\n",
      " ---> 6ccb9e73c64b\n",
      "Successfully built 6ccb9e73c64b\n",
      "Successfully tagged gcr.io/jk-mlops-dev/image_classifier:latest\n",
      "PUSH\n",
      "Pushing gcr.io/jk-mlops-dev/image_classifier:latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/image_classifier]\n",
      "1c8708ce98be: Preparing\n",
      "a40015af016f: Preparing\n",
      "ea7a404fee01: Preparing\n",
      "6a5c1aba1004: Preparing\n",
      "2326ebaab673: Preparing\n",
      "2afbe00a2c26: Preparing\n",
      "8cc68a31e4c1: Preparing\n",
      "6cbf095938e9: Preparing\n",
      "cea209c34bb9: Preparing\n",
      "fbd8cc1dc001: Preparing\n",
      "aec69efefae2: Preparing\n",
      "b25743b4c186: Preparing\n",
      "3f446960264e: Preparing\n",
      "3c491da8642f: Preparing\n",
      "d7b25025454f: Preparing\n",
      "2fb8088bc1ab: Preparing\n",
      "c961a9b591f5: Preparing\n",
      "b6fd2e80fdc9: Preparing\n",
      "626800c31be3: Preparing\n",
      "eca318b890fc: Preparing\n",
      "03aea7c9e3d1: Preparing\n",
      "53194dce1444: Preparing\n",
      "ef8330bcc944: Preparing\n",
      "964ee116c0c0: Preparing\n",
      "7a694df0ad6c: Preparing\n",
      "3fd9df553184: Preparing\n",
      "805802706667: Preparing\n",
      "2afbe00a2c26: Waiting\n",
      "8cc68a31e4c1: Waiting\n",
      "6cbf095938e9: Waiting\n",
      "cea209c34bb9: Waiting\n",
      "fbd8cc1dc001: Waiting\n",
      "aec69efefae2: Waiting\n",
      "b25743b4c186: Waiting\n",
      "3f446960264e: Waiting\n",
      "3c491da8642f: Waiting\n",
      "d7b25025454f: Waiting\n",
      "2fb8088bc1ab: Waiting\n",
      "c961a9b591f5: Waiting\n",
      "b6fd2e80fdc9: Waiting\n",
      "626800c31be3: Waiting\n",
      "eca318b890fc: Waiting\n",
      "03aea7c9e3d1: Waiting\n",
      "53194dce1444: Waiting\n",
      "ef8330bcc944: Waiting\n",
      "964ee116c0c0: Waiting\n",
      "7a694df0ad6c: Waiting\n",
      "3fd9df553184: Waiting\n",
      "805802706667: Waiting\n",
      "ea7a404fee01: Layer already exists\n",
      "2326ebaab673: Layer already exists\n",
      "6a5c1aba1004: Layer already exists\n",
      "8cc68a31e4c1: Layer already exists\n",
      "2afbe00a2c26: Layer already exists\n",
      "6cbf095938e9: Layer already exists\n",
      "cea209c34bb9: Layer already exists\n",
      "aec69efefae2: Layer already exists\n",
      "fbd8cc1dc001: Layer already exists\n",
      "3f446960264e: Layer already exists\n",
      "3c491da8642f: Layer already exists\n",
      "1c8708ce98be: Pushed\n",
      "b25743b4c186: Layer already exists\n",
      "2fb8088bc1ab: Layer already exists\n",
      "d7b25025454f: Layer already exists\n",
      "c961a9b591f5: Layer already exists\n",
      "b6fd2e80fdc9: Layer already exists\n",
      "eca318b890fc: Layer already exists\n",
      "626800c31be3: Layer already exists\n",
      "03aea7c9e3d1: Layer already exists\n",
      "53194dce1444: Layer already exists\n",
      "7a694df0ad6c: Layer already exists\n",
      "964ee116c0c0: Layer already exists\n",
      "3fd9df553184: Layer already exists\n",
      "ef8330bcc944: Layer already exists\n",
      "805802706667: Layer already exists\n",
      "a40015af016f: Pushed\n",
      "latest: digest: sha256:b6c2df4739f027cc4ccb61f7e65ebc735f94872672c679236b46c6e48cd921c4 size: 5989\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                     IMAGES                                          STATUS\n",
      "57919f40-b3e9-48d4-8858-c92d5c6c5283  2020-12-08T00:54:52+00:00  8M16S     gs://jk-mlops-dev_cloudbuild/source/1607388892.08279-dec718e2d26d41a5a702882b460ad99d.tgz  gcr.io/jk-mlops-dev/image_classifier (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag {IMAGE_URI} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting training jobs\n",
    "\n",
    "You are now ready to submit training jobs. You will submit two jobs. First, you will submit a custom training job that runs your custom container once using a single set of hyperparameters. Then, you will submit a hyperparameter tuning job that will use your custom container image to run multiple training trials using a number of hyperparameter combinations selected by AI Platform Training. In both cases you will use AI Platform TensorBoard to monitor the execution of training.\n",
    "\n",
    "\n",
    "Note that a custom training job and a hyperparameter tuning job are distinct resource types in AI Platform Training (Unified) API. The custom training job is the `CustomJob` resource and the hyperparameter tuning job is the `HyperParameterTuningJob` resource. Refer to the [AI Platform API documentation](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1beta1/types.html) for the detailed information about the job specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a custom training job\n",
    "\n",
    "The `worker_pool_specs` section of the job specification defines the configuration of the compute infrastructure to run the training job on on the configuration of a custom training container. In our case, the job will run on a single `n1-standard-8` node equipped with a single NVidia T4 GPU. The job will use the container image created in the previous steps configured to train for 20 epochs. All other arguments of the training script are left at their defaults. The `base_output_directory` section of the job specs defines the location for the TensorBoard logs. The value provided in the request (`BASE_OUTPUT_DIR`) will be exposed to the training script as the `AIP_TENSORBOARD_LOG_DIR` evironment variable. The `tensorboard` field of the job spec is set to a full name of the TensorBoard instance created in the notebook's setup section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"_CUSTOM_JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "BASE_OUTPUT_DIR = f'gs://{GCS_BUCKET_NAME}/{JOB_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/895222332033/locations/us-central1/customJobs/485843401988636672',\n",
       " 'displayName': '_CUSTOM_JOB_20201208_010310',\n",
       " 'jobSpec': {'workerPoolSpecs': [{'machineSpec': {'machineType': 'n1-standard-8',\n",
       "     'acceleratorType': 'NVIDIA_TESLA_T4',\n",
       "     'acceleratorCount': 1},\n",
       "    'replicaCount': '1',\n",
       "    'diskSpec': {'bootDiskType': 'pd-standard', 'bootDiskSizeGb': 100},\n",
       "    'containerSpec': {'imageUri': 'gcr.io/jk-mlops-dev/image_classifier:latest',\n",
       "     'args': ['--num-epochs=20']}}],\n",
       "  'serviceAccount': 'aip-training@jk-mlops-dev.iam.gserviceaccount.com',\n",
       "  'baseOutputDirectory': {'outputUriPrefix': 'gs://jk-mlops-dev-tensorboard-logs/_CUSTOM_JOB_20201208_010310'},\n",
       "  'tensorboard': 'projects/895222332033/locations/us-central1/tensorboards/2152439146906386432'},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2020-12-08T01:03:11.582907Z',\n",
       " 'updateTime': '2020-12-08T01:03:11.582907Z'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = f'{CAIP_PARENT_BETA}/customJobs'\n",
    "\n",
    "request_body = {\n",
    "    'display_name': JOB_NAME,\n",
    "    'job_spec': {\n",
    "        'worker_pool_specs': [\n",
    "            {\n",
    "                'replica_count': 1,\n",
    "                'machine_spec': {\n",
    "                    'machine_type': 'n1-standard-8',\n",
    "                    'accelerator_type': 'NVIDIA_TESLA_T4',\n",
    "                    'accelerator_count': 1\n",
    "                },\n",
    "                'container_spec': {\n",
    "                    'image_uri': IMAGE_URI,\n",
    "                    'args': [\n",
    "                        f'--num-epochs=20'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        'base_output_directory': {\n",
    "            'output_uri_prefix': BASE_OUTPUT_DIR,\n",
    "        },\n",
    "        'service_account': SA_EMAIL,\n",
    "        'tensorboard': tensorboard_id\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = authed_session.post(api_url, data=json.dumps(request_body))\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the job was successfully started you can monitor the progress of training using Tensorboard dashboards. \n",
    "\n",
    "Find your job in [Cloud Console](https://pantheon.corp.google.com/ai/platform/training-pipelines). Click on the job name to display the job's details. You will see the *OPEN TENSORBOARD* link in the upper left section of the page. Click on it to open the TensorBoard instance. Note that it may take a few minutes before the job starts running your training script and the logs are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a hyperparameter tuning job\n",
    "\n",
    "The `worker_pool_specs` of the job spec is the same as in the custom job spec. Since this is a hypertuning job there are additional sections that define the hyperparameter tuning configuration.\n",
    "\n",
    "In our example, the job will attempt to maximize accuracy using the `grid search` algorithm. The job expects that the training script reports the `accuracy` metric using the `hypertune` package. Recall that the training scripts reports the validation accuracy at the end of each epoch. \n",
    "\n",
    "The job is configured to tune two hyperparameters: `batch-size` and `num-layers`. The `batch-size` parameter is the batch size used in the scripts training loop and the `num-layers` parameter is a number of hidden layers in the model's FCNN classification head. Both parameters are passed to the script as command line arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/895222332033/locations/us-central1/hyperparameterTuningJobs/5524949172551155712',\n",
       " 'displayName': 'HYPER_JOB_20201208_012106',\n",
       " 'studySpec': {'metrics': [{'metricId': 'accuracy', 'goal': 'MAXIMIZE'}],\n",
       "  'parameters': [{'parameterId': 'batch-size',\n",
       "    'discreteValueSpec': {'values': [32, 64, 128]},\n",
       "    'scaleType': 'UNIT_LINEAR_SCALE'},\n",
       "   {'parameterId': 'num-layers',\n",
       "    'discreteValueSpec': {'values': [64, 128]},\n",
       "    'scaleType': 'UNIT_LINEAR_SCALE'}],\n",
       "  'algorithm': 'GRID_SEARCH'},\n",
       " 'maxTrialCount': 6,\n",
       " 'parallelTrialCount': 3,\n",
       " 'trialJobSpec': {'workerPoolSpecs': [{'machineSpec': {'machineType': 'n1-standard-8',\n",
       "     'acceleratorType': 'NVIDIA_TESLA_T4',\n",
       "     'acceleratorCount': 1},\n",
       "    'replicaCount': '1',\n",
       "    'diskSpec': {'bootDiskType': 'pd-standard', 'bootDiskSizeGb': 100},\n",
       "    'containerSpec': {'imageUri': 'gcr.io/jk-mlops-dev/image_classifier:latest',\n",
       "     'args': ['--num-epochs=20']}}],\n",
       "  'serviceAccount': 'aip-training@jk-mlops-dev.iam.gserviceaccount.com',\n",
       "  'baseOutputDirectory': {'outputUriPrefix': 'gs://jk-mlops-dev-tensorboard-logs/_CUSTOM_JOB_20201208_010310'},\n",
       "  'tensorboard': 'projects/895222332033/locations/us-central1/tensorboards/2152439146906386432'},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2020-12-08T01:21:07.669843Z',\n",
       " 'updateTime': '2020-12-08T01:21:07.669843Z'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = f'{CAIP_PARENT_BETA}/hyperparameterTuningJobs'\n",
    "JOB_NAME = \"HYPER_JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "request_body = {\n",
    "    'display_name': JOB_NAME,\n",
    "    'study_spec' : {\n",
    "        'metrics': [\n",
    "            {\n",
    "                'metric_id': 'accuracy',\n",
    "                'goal': 'MAXIMIZE'\n",
    "            }\n",
    "        ],\n",
    "        'parameters': [\n",
    "            {\n",
    "                'parameter_id': 'batch-size',\n",
    "                'discrete_value_spec': {'values': [32, 64, 128]},\n",
    "                'scale_type': 'UNIT_LINEAR_SCALE'\n",
    "            },\n",
    "            {\n",
    "                'parameter_id': 'num-layers',\n",
    "                'discrete_value_spec': {'values': [64, 128]},\n",
    "                'scale_type': 'UNIT_LINEAR_SCALE'\n",
    "            }\n",
    "        ],\n",
    "    'algorithm':'GRID_SEARCH'\n",
    "    },\n",
    "    'maxTrialCount': 6,\n",
    "    'parallelTrialCount': 3,\n",
    "    'trial_job_spec': {\n",
    "        'worker_pool_specs': [\n",
    "            {\n",
    "                'replica_count': 1,\n",
    "                'machine_spec': {\n",
    "                    'machine_type': 'n1-standard-8',\n",
    "                    'accelerator_type': 'NVIDIA_TESLA_T4',\n",
    "                    'accelerator_count': 1\n",
    "                },\n",
    "                'container_spec': {\n",
    "                    'image_uri': IMAGE_URI,\n",
    "                    'args': [\n",
    "                        f'--num-epochs=20'\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        'base_output_directory': {\n",
    "            'output_uri_prefix': BASE_OUTPUT_DIR,\n",
    "        },\n",
    "        'service_account': SA_EMAIL,\n",
    "        'tensorboard': tensorboard_id\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = authed_session.post(api_url, data=json.dumps(request_body))\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all tensorboards in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = f'{CAIP_PARENT_ALPHA}/tensorboards'\n",
    "\n",
    "response = authed_session.get(api_url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a TensorBoard resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/895222332033/locations/us-central1/operations/1765659543557111808',\n",
       " 'metadata': {'@type': 'type.googleapis.com/google.cloud.aiplatform.v1alpha1.DeleteOperationMetadata',\n",
       "  'genericMetadata': {'createTime': '2020-12-08T00:50:34.594360Z',\n",
       "   'updateTime': '2020-12-08T00:50:34.594360Z'}},\n",
       " 'done': True,\n",
       " 'response': {'@type': 'type.googleapis.com/google.protobuf.Empty'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_id = '7266276523785584640'\n",
    "\n",
    "api_url = f'{CAIP_PARENT_ALPHA}/tensorboards/{tensorboard_id}'\n",
    "\n",
    "response = authed_session.delete(api_url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
